## 選擇不同嵌入模型
使用參數***embeddings***便可以選擇不同的嵌入模型，預設是***openai:text-embedding-ada-002***.



## 範例




### 1. openai 

```python!=
akasha.Doc_QA()
ak.get_response(dir_path, prompt, embeddings="openai:text-embedding-ada-002",)
```

</br>
</br>

### 2. huggingface 

```python!=
ak = akasha.Doc_QA(embeddings="huggingface:all-MiniLM-L6-v2")
resposne = ak.get_response(dir_path, prompt)
```
</br>
</br>



## 可使用的模型
:::info
每個嵌入模型都有max sequence length，超過的話後面的文字就會被截斷，不會拿進去做嵌入。
:::
```python!=
openai_emd = "openai:text-embedding-ada-002"  # need environment variable "OPENAI_API_KEY"  # 8192 max seq length
huggingface_emd = "hf:all-MiniLM-L6-v2" 
text2vec_ch_emd = "hf:shibing624/text2vec-base-chinese"   # 128 max seq length 
text2vec_mul_emd = "hf:shibing624/text2vec-base-multilingual"  # 256 max seq length
text2vec_ch_para_emd = "hf:shibing624/text2vec-base-chinese-paraphrase" # perform better for long text, 256 max seq length
bge_en_emd = "hf:BAAI/bge-base-en-v1.5"  # 512 max seq length
bge_ch_emd = "hf:BAAI/bge-base-zh-v1.5"  # 512 max seq length

rerank_base = "rerank:BAAI/bge-reranker-base"    # 512 max seq length
rerank_large = "rerank:BAAI/bge-reranker-large"  # 512 max seq length

```

</br>
</br>
</br>
</br>


## 自訂嵌入模型
如果你想使用其他模型，可以建立一個輸入是***texts:list***的函數，代表的是文件庫中所有分割好的文字段落，此函數需回傳embedding之後每段文字的向量，並將此函數作為***embeddings***參數



### example
我們建立一個test_embed函數，並可以將它作為參數輸入進get_response回答問題
```python!=
def test_embed(texts:list)->list:

    from sentence_transformers import SentenceTransformer
    mdl = SentenceTransformer('BAAI/bge-large-zh-v1.5')
    embeds =  mdl.encode(texts,normalize_embeddings=True)

    
    return embeds

doc_path = "./mic/"
prompt = "五軸是什麼?"

qa = akasha.Doc_QA(verbose=True, search_type = "svm", embeddings = test_embed)
qa.get_response(doc_path= doc_path, prompt = prompt)
```